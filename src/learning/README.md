# Learning ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

é€†å¼·åŒ–å­¦ç¿’ï¼ˆInverse Reinforcement Learning, IRLï¼‰ã‚’ç”¨ã„ãŸã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼å„ªå…ˆé †ä½ä»˜ã‘ãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ã™ã€‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¼ã®è¡Œå‹•ã‹ã‚‰å„ªå…ˆé †ä½ã®åˆ¤æ–­åŸºæº–ã‚’å­¦ç¿’ã—ã€æ–°ã—ã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å„ªå…ˆåº¦ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚

## ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

| ãƒ•ã‚¡ã‚¤ãƒ« | èª¬æ˜ |
|---------|------|
| `irl_models.py` | IRLãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…ã¨ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¯ãƒ©ã‚¹ |
| `temporal_weight_analysis.py` | æ™‚ç³»åˆ—é‡ã¿åˆ†æï¼ˆã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§IRLé‡ã¿å¤‰å‹•ã‚’è¿½è·¡ï¼‰ |
| `temporal_model_evaluation.py` | æ™‚ç³»åˆ—ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ï¼ˆBalanced Random Forestã§æ­£è² ä¾‹ã‚’åˆ†é¡ï¼‰ |

## ğŸ§  ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

### æœ€å¤§ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼é€†å¼·åŒ–å­¦ç¿’ (MaxEnt IRL)
- **å°‚é–€å®¶ã®è¡Œå‹•æ¨¡å€£**: ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¼ã®å„ªå…ˆé †ä½ä»˜ã‘è¡Œå‹•ã‚’å­¦ç¿’
- **ç‰¹å¾´é‡é‡ã¿æ¨å®š**: å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®é‡è¦åº¦ã‚’è‡ªå‹•è¨ˆç®—
- **ç¢ºç‡çš„ãƒ¢ãƒ‡ãƒ«**: ä¸ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®ã—ãŸå„ªå…ˆåº¦äºˆæ¸¬

## ğŸ”§ ä¸»è¦ã‚¯ãƒ©ã‚¹

### `MaxEntIRLModel`
é€†å¼·åŒ–å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…

```python
class MaxEntIRLModel:
    def __init__(self, learning_rate=0.01, max_iterations=1000, tolerance=1e-6):
        """
        Args:
            learning_rate: å­¦ç¿’ç‡
            max_iterations: æœ€å¤§åå¾©å›æ•°  
            tolerance: åæŸåˆ¤å®šé–¾å€¤
        """
```

**ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰:**
- `fit(features, priorities)`: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
- `predict_priority_scores(features)`: å„ªå…ˆåº¦äºˆæ¸¬
- `save_model(path)`, `load_model(path)`: ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿

### `ReviewPriorityDataProcessor`
ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç®¡ç†

```python
class ReviewPriorityDataProcessor:
    def load_openstack_data(self) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """OpenStackãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
        
    def extract_features(self, changes_df, analysis_time) -> pd.DataFrame:
        """ç‰¹å¾´é‡æŠ½å‡º"""
```

## ğŸ“Š å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹

### 1. ãƒ‡ãƒ¼ã‚¿æº–å‚™
```python
# ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
processor = ReviewPriorityDataProcessor()
changes_df, releases_df = processor.load_openstack_data()

# å­¦ç¿’ã‚¤ãƒ™ãƒ³ãƒˆã®æŠ½å‡º
events = extract_learning_events(changes_df, bot_names)
```

### 2. ç‰¹å¾´é‡æŠ½å‡º
```python
# 16æ¬¡å…ƒç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«ã®ç”Ÿæˆ
features_df = processor.extract_features(changes_df, analysis_time)
feature_columns = [
    'bug_fix_confidence', 'lines_added', 'lines_deleted', 'files_changed',
    'elapsed_time', 'revision_count', 'test_code_presence',
    'past_report_count', 'recent_report_count', 'merge_rate', 'recent_merge_rate',
    'days_to_major_release', 'open_ticket_count', 'reviewed_lines_in_period',
    'refactoring_confidence', 'uncompleted_requests'
]
```

### 3. å„ªå…ˆåº¦ãƒ©ãƒ™ãƒ«ç”Ÿæˆ
```python
# ãƒ¬ãƒ“ãƒ¥ãƒ¼æ™‚åˆ»ã«åŸºã¥ãå„ªå…ˆåº¦é‡ã¿è¨ˆç®—
priorities = calculate_review_priorities(open_changes, current_time, bot_names)
```

### 4. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
```python
# IRLãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
model = MaxEntIRLModel(learning_rate=0.01, max_iterations=100)
model.feature_names = feature_columns
training_stats = model.fit(X, y)
```

## ğŸ“ˆ çµæœå‡ºåŠ›

### å­¦ç¿’çµæœJSON
```json
{
  "date_range": {"start": "2024-01-01", "end": "2024-12-31"},
  "timestamp": "20241001_123000",
  "data_summary": {
    "total_learning_events": 1500,
    "successful_learning_data": 1350,
    "total_training_samples": 8000,
    "feature_dimensions": 16,
    "projects_analyzed": 6,
    "projects_failed": 0
  },
  "project_results": {
    "nova": {
      "training_stats": {
        "converged": true,
        "final_objective": 1.23,
        "iterations": 45
      },
      "model_path": "/path/to/irl_model_nova_20241001_20241231.pkl",
      "data_summary": {
        "training_samples": 2000,
        "learning_events": 350
      },
      "feature_weights": {
        "bug_fix_confidence": 0.15,
        "lines_added": 0.08,
        "recent_merge_rate": 0.42,
        "days_to_major_release": -0.25,
        ...
      }
    }
  }
}
```

### é‡ã¿è§£é‡ˆ
- **æ­£ã®é‡ã¿**: é«˜å„ªå…ˆåº¦è¦å› ï¼ˆä¾‹: `recent_merge_rate: 0.42`ï¼‰
- **è² ã®é‡ã¿**: ä½å„ªå…ˆåº¦è¦å› ï¼ˆä¾‹: `days_to_major_release: -0.25`ï¼‰

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬çš„ãªå­¦ç¿’ãƒ»äºˆæ¸¬

```python
from src.learning.irl_models import run_temporal_irl_analysis

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ¥IRLå­¦ç¿’ã®å®Ÿè¡Œ
projects = ['nova', 'neutron', 'swift', 'cinder', 'keystone', 'glance']
results = run_temporal_irl_analysis(projects)

# çµæœã®ç¢ºèª
for project, result in results['project_results'].items():
    print(f"{project}: åæŸ={result['training_stats']['converged']}")
    print(f"é‡è¦ç‰¹å¾´é‡: {max(result['feature_weights'].items(), key=lambda x: x[1])}")
```

### å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬

```python
# ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
model = MaxEntIRLModel()
model.load_model("irl_model_nova_20241001_20241231.pkl")

# æ–°ã—ã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å„ªå…ˆåº¦äºˆæ¸¬
new_features = extract_features(new_review_data)
priority_scores = model.predict_priority_scores(new_features)
```

## ğŸ“Š è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹

### å­¦ç¿’å“è³ªã®æŒ‡æ¨™

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | èª¬æ˜ | è‰¯å¥½ãªå€¤ |
|-----------|------|----------|
| `converged` | å­¦ç¿’ã®åæŸ | `True` |
| `final_objective` | ç›®çš„é–¢æ•°ã®æœ€çµ‚å€¤ | 0.0-1.5 |
| `iterations` | åå¾©å›æ•° | 10-100 |

### ãƒ¢ãƒ‡ãƒ«æ€§èƒ½
- **äºˆæ¸¬ç²¾åº¦**: å°‚é–€å®¶ã®åˆ¤æ–­ã¨ã®ä¸€è‡´ç‡
- **ç‰¹å¾´é‡é‡è¦åº¦**: è§£é‡ˆå¯èƒ½ãªé‡ã¿åˆ†å¸ƒ
- **æ±åŒ–æ€§èƒ½**: æœªè¦‹ãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½

## âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

### å­¦ç¿’æ™‚é–“
- **å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿** (100ã‚µãƒ³ãƒ—ãƒ«): ~1ç§’
- **ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿** (1,000ã‚µãƒ³ãƒ—ãƒ«): ~10ç§’  
- **å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿** (10,000ã‚µãƒ³ãƒ—ãƒ«): ~60ç§’

### ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
- **åŸºæœ¬ãƒ¢ãƒ‡ãƒ«**: ~2MB
- **ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿**: ~10MB (1,000ã‚µãƒ³ãƒ—ãƒ«)
- **å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«**: ~1.4KB (ä¿å­˜æ™‚)

## ğŸ”§ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´

```python
# å­¦ç¿’ç‡ã®èª¿æ•´
model = MaxEntIRLModel(
    learning_rate=0.001,     # å°ã•ãã™ã‚‹ã¨å®‰å®šã€é…ã„
    max_iterations=500,      # å¤šãã™ã‚‹ã¨ç²¾åº¦å‘ä¸Šã€æ™‚é–“å¢—
    tolerance=1e-8           # å°ã•ãã™ã‚‹ã¨å³å¯†ã€æ™‚é–“å¢—
)
```

### æ¨å¥¨è¨­å®š
- **é«˜ç²¾åº¦**: `learning_rate=0.001, max_iterations=1000, tolerance=1e-8`
- **é«˜é€Ÿ**: `learning_rate=0.1, max_iterations=100, tolerance=1e-4`
- **ãƒãƒ©ãƒ³ã‚¹**: `learning_rate=0.01, max_iterations=500, tolerance=1e-6`

## ğŸ¯ å®Ÿç”¨çš„ãªå¿œç”¨

### 1. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å„ªå…ˆé †ä½ä»˜ã‘
```python
# æ–°ç€ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å„ªå…ˆåº¦è¨ˆç®—
def prioritize_new_reviews(new_reviews):
    features = extract_features(new_reviews)
    scores = model.predict_priority_scores(features)
    return sorted(zip(new_reviews, scores), key=lambda x: x[1], reverse=True)
```

### 2. ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼æ¨è–¦
```python
# é«˜å„ªå…ˆåº¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼æ¨è–¦
def recommend_reviewers(high_priority_reviews, reviewers_expertise):
    # ç‰¹å¾´é‡ã«åŸºã¥ã„ã¦ãƒãƒƒãƒãƒ³ã‚°
    return match_reviewers_to_reviews(high_priority_reviews, reviewers_expertise)
```

### 3. ãƒªã‚½ãƒ¼ã‚¹é…åˆ†
```python
# é–‹ç™ºãƒªã‚½ãƒ¼ã‚¹ã®é…åˆ†æ±ºå®š
def allocate_resources(review_queue, available_resources):
    priorities = [model.predict_priority_scores(r.features)[0] for r in review_queue]
    return optimize_resource_allocation(review_queue, priorities, available_resources)
```

## âš ï¸ æ³¨æ„äº‹é …

1. **ãƒ‡ãƒ¼ã‚¿å“è³ª**: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®è³ªãŒçµæœã«å¤§ããå½±éŸ¿
2. **ãƒ‰ãƒ¡ã‚¤ãƒ³ä¾å­˜**: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç‰¹æ€§ã«å¿œã˜ãŸèª¿æ•´ãŒå¿…è¦
3. **ç¶™ç¶šå­¦ç¿’**: æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§ã®å®šæœŸçš„ãªå†å­¦ç¿’
4. **è§£é‡ˆæ€§**: é‡ã¿ã®æ„å‘³ã‚’é©åˆ‡ã«ç†è§£ã—ã¦æ´»ç”¨

## ğŸ”¬ ç ”ç©¶ãƒ»æ‹¡å¼µã®æ–¹å‘æ€§

- **æ·±å±¤å­¦ç¿’**: ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ™ãƒ¼ã‚¹ã®IRL
- **å¤šç›®çš„æœ€é©åŒ–**: è¤‡æ•°ã®è©•ä¾¡è»¸ã®åŒæ™‚è€ƒæ…®
- **å¼·åŒ–å­¦ç¿’**: å‹•çš„ãªå„ªå…ˆé †ä½èª¿æ•´

## ğŸ“Š æ™‚ç³»åˆ—ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ (`temporal_model_evaluation.py`)

### æ¦‚è¦
Balanced Random Forestã‚’ç”¨ã„ã¦ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã”ã¨ã«æ­£è² ä¾‹ã‚’å®šç¾©ã—ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼å„ªå…ˆé †ä½ä»˜ã‘ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ã¾ã™ã€‚

### æ­£è² ä¾‹ã®å®šç¾©
- **æ­£ä¾‹ï¼ˆãƒ©ãƒ™ãƒ«=1ï¼‰**: ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æœŸé–“ä¸­ã«1å›ä»¥ä¸Šãƒ¬ãƒ“ãƒ¥ãƒ¼ã•ã‚ŒãŸPR
- **è² ä¾‹ï¼ˆãƒ©ãƒ™ãƒ«=0ï¼‰**: ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æœŸé–“ä¸­ã«1åº¦ã‚‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ã•ã‚Œãªã‹ã£ãŸPR

### ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
- PRå˜ä½ã§å­¦ç¿’:è©•ä¾¡ = 8:2ã«åˆ†å‰²
- `random_state=42`ã§å†ç¾æ€§ã‚’ç¢ºä¿
- åŒã˜PRãŒå­¦ç¿’ã¨è©•ä¾¡ã®ä¸¡æ–¹ã«å«ã¾ã‚Œãªã„ã‚ˆã†ä¿è¨¼

### è©•ä¾¡æŒ‡æ¨™
- **Precisionï¼ˆé©åˆç‡ï¼‰**: äºˆæ¸¬ã—ãŸæ­£ä¾‹ã®ã†ã¡å®Ÿéš›ã«æ­£ä¾‹ã ã£ãŸå‰²åˆ
- **Recallï¼ˆå†ç¾ç‡ï¼‰**: å®Ÿéš›ã®æ­£ä¾‹ã®ã†ã¡æ­£ã—ãäºˆæ¸¬ã§ããŸå‰²åˆ  
- **F1 Scoreï¼ˆFå€¤ï¼‰**: Precisionã¨Recallã®èª¿å’Œå¹³å‡

### å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
`data/temporal_evaluation/`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ï¼š
- `temporal_evaluation_{project}.csv`: ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã”ã¨ã®è©•ä¾¡æŒ‡æ¨™
- `temporal_evaluation_{project}.json`: å…¨ä½“ã®ã‚µãƒãƒªãƒ¼çµ±è¨ˆ
- `temporal_evaluation_{project}.pdf`: è©•ä¾¡çµæœã®å¯è¦–åŒ–ãƒ¬ãƒãƒ¼ãƒˆ

### ä½¿ç”¨ä¾‹
```python
from src.learning.temporal_model_evaluation import run_temporal_model_evaluation

# å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è©•ä¾¡
results = run_temporal_model_evaluation()

# ç‰¹å®šãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è©•ä¾¡
results = run_temporal_model_evaluation(projects=['nova', 'neutron'])
```
- **èª¬æ˜å¯èƒ½AI**: ã‚ˆã‚Šè©³ç´°ãªåˆ¤æ–­æ ¹æ‹ ã®æä¾›
