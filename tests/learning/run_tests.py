"""
IRLãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

pytest ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„ç’°å¢ƒã§ã‚‚å®Ÿè¡Œå¯èƒ½ãª
ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚¹ãƒˆãƒ©ãƒ³ãƒŠãƒ¼ã‚’æä¾›ã—ã¾ã™ã€‚
"""

import sys
import os
import traceback
from typing import List, Callable, Tuple

# ãƒ‘ã‚¹ã®è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

# ãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from tests.learning.test_helpers import (
        create_mock_change_data,
        create_mock_features_dataframe,
        create_learning_event_scenario,
        assert_valid_irl_training_stats,
        assert_valid_priority_weights
    )
    print("âœ“ ãƒ†ã‚¹ãƒˆãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âœ— ãƒ†ã‚¹ãƒˆãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from src.learning.irl_models import (
        MaxEntIRLModel,
        ReviewPriorityDataProcessor,
        is_bot_author,
        calculate_review_priorities
    )
    print("âœ“ IRLãƒ¢ãƒ‡ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âœ— IRLãƒ¢ãƒ‡ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")


class SimpleTestRunner:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚¹ãƒˆãƒ©ãƒ³ãƒŠãƒ¼"""
    
    def __init__(self):
        self.passed = 0
        self.failed = 0
        self.errors = []
    
    def run_test(self, test_func: Callable, test_name: str):
        """å˜ä¸€ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        try:
            print(f"å®Ÿè¡Œä¸­: {test_name}")
            test_func()
            self.passed += 1
            print(f"âœ“ {test_name} - PASSED")
        except AssertionError as e:
            self.failed += 1
            error_msg = f"âœ— {test_name} - FAILED: {str(e)}"
            print(error_msg)
            self.errors.append(error_msg)
        except Exception as e:
            self.failed += 1
            error_msg = f"âœ— {test_name} - ERROR: {str(e)}"
            print(error_msg)
            self.errors.append(error_msg)
            print(traceback.format_exc())
    
    def print_summary(self):
        """ãƒ†ã‚¹ãƒˆçµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        total = self.passed + self.failed
        print(f"\n=== ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼ ===")
        print(f"å®Ÿè¡Œ: {total}")
        print(f"æˆåŠŸ: {self.passed}")
        print(f"å¤±æ•—: {self.failed}")
        
        if self.errors:
            print(f"\n=== ã‚¨ãƒ©ãƒ¼è©³ç´° ===")
            for error in self.errors:
                print(error)


def test_is_bot_author():
    """ãƒœãƒƒãƒˆåˆ¤å®šé–¢æ•°ã®ãƒ†ã‚¹ãƒˆ"""
    bot_names = ['jenkins', 'zuul', 'ci-bot']
    
    # ãƒœãƒƒãƒˆã®å ´åˆ
    assert is_bot_author('jenkins-user', bot_names) == True
    assert is_bot_author('zuul-bot', bot_names) == True
    assert is_bot_author('CI-BOT', bot_names) == True
    
    # ãƒœãƒƒãƒˆã§ãªã„å ´åˆ
    assert is_bot_author('john.doe', bot_names) == False
    assert is_bot_author('developer', bot_names) == False
    
    # ç©ºã®å ´åˆ
    assert is_bot_author('', bot_names) == False
    assert is_bot_author('test', []) == False


def test_maxent_irl_model_basic():
    """MaxEntIRLModelã®åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
    import numpy as np
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    model = MaxEntIRLModel(learning_rate=0.01, max_iterations=10, tolerance=1e-6)
    assert model.learning_rate == 0.01
    assert model.max_iterations == 10
    assert model.weights is None
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
    np.random.seed(42)
    n_samples, n_features = 20, 5
    X = np.random.randn(n_samples, n_features)
    y = np.random.rand(n_samples)
    y = y / np.sum(y)  # æ­£è¦åŒ–
    
    # å­¦ç¿’
    model.feature_names = [f'feature_{i}' for i in range(n_features)]
    training_stats = model.fit(X, y)
    
    # å­¦ç¿’çµæœã®æ¤œè¨¼
    assert model.weights is not None
    assert len(model.weights) == n_features
    assert_valid_irl_training_stats(training_stats)
    
    # äºˆæ¸¬
    predictions = model.predict_priority_scores(X)
    assert len(predictions) == n_samples
    assert not np.any(np.isnan(predictions))


def test_calculate_review_priorities():
    """å„ªå…ˆé †ä½è¨ˆç®—ã®ãƒ†ã‚¹ãƒˆ"""
    import pandas as pd
    from datetime import datetime, timezone
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ï¼ˆUTCã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ä»˜ãï¼‰
    test_data = [
        {
            'change_number': 1,
            'messages': [
                {
                    'author': {'name': 'user1'},
                    'date': '2022-01-01T14:00:00+00:00'  # 2æ™‚é–“å¾Œ
                }
            ]
        },
        {
            'change_number': 2,
            'messages': [
                {
                    'author': {'name': 'user2'},
                    'date': '2022-01-01T13:00:00+00:00'  # 1æ™‚é–“å¾Œ
                }
            ]
        },
        {
            'change_number': 3,
            'messages': []  # ãƒ¬ãƒ“ãƒ¥ãƒ¼äºˆå®šãªã—
        }
    ]
    
    open_changes = pd.DataFrame(test_data)
    current_time = datetime(2022, 1, 1, 12, 0, 0, tzinfo=timezone.utc)
    bot_names = ['jenkins']
    
    priorities = calculate_review_priorities(open_changes, current_time, bot_names)
    
    # æ¤œè¨¼
    assert_valid_priority_weights(priorities, 3)
    
    # é †åºã®ç¢ºèª
    assert priorities['2'] > priorities['1']  # user2ãŒæ—©ããƒ¬ãƒ“ãƒ¥ãƒ¼äºˆå®š
    assert priorities['1'] > priorities['3']  # user1ãŒãƒ¬ãƒ“ãƒ¥ãƒ¼äºˆå®šãªã—ã‚ˆã‚Šé«˜ã„


def test_mock_data_generation():
    """ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ"""
    from datetime import datetime
    
    # Changeãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
    change_data = create_mock_change_data(
        change_number=12345,
        created_time=datetime(2022, 1, 1, 10, 0, 0),
        component="test_component"
    )
    
    assert change_data['change_number'] == 12345
    assert change_data['component'] == "test_component"
    assert 'owner' in change_data
    assert 'messages' in change_data
    
    # ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ç”Ÿæˆ
    features_df = create_mock_features_dataframe([1001, 1002, 1003])
    
    assert len(features_df) == 3
    assert 'change_number' in features_df.columns
    assert 'priority_weight' in features_df.columns
    assert all(0 <= w <= 1 for w in features_df['priority_weight'])


def test_learning_event_scenario():
    """å­¦ç¿’ã‚¤ãƒ™ãƒ³ãƒˆã‚·ãƒŠãƒªã‚ªã®ãƒ†ã‚¹ãƒˆ"""
    changes_df, expected_events = create_learning_event_scenario()
    
    assert len(changes_df) == 3
    assert len(expected_events) == 3
    
    # å…¨ã¦ã®Changeã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå«ã¾ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
    for _, change in changes_df.iterrows():
        assert 'messages' in change
        assert isinstance(change['messages'], list)


def test_data_processor_initialization():
    """ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
    from unittest.mock import patch
    
    with patch('src.learning.irl_models.ReviewStatusAnalyzer'):
        processor = ReviewPriorityDataProcessor()
        assert processor is not None


def run_all_tests():
    """å…¨ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
    runner = SimpleTestRunner()
    
    # åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
    runner.run_test(test_is_bot_author, "ãƒœãƒƒãƒˆåˆ¤å®šæ©Ÿèƒ½")
    runner.run_test(test_maxent_irl_model_basic, "MaxEntIRLModelåŸºæœ¬æ©Ÿèƒ½")
    runner.run_test(test_calculate_review_priorities, "å„ªå…ˆé †ä½è¨ˆç®—")
    runner.run_test(test_mock_data_generation, "ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ")
    runner.run_test(test_learning_event_scenario, "å­¦ç¿’ã‚¤ãƒ™ãƒ³ãƒˆã‚·ãƒŠãƒªã‚ª")
    runner.run_test(test_data_processor_initialization, "ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼åˆæœŸåŒ–")
    
    runner.print_summary()
    return runner.failed == 0


if __name__ == '__main__':
    print("=== IRLãƒ¢ãƒ‡ãƒ« ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ ===")
    print("ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ pytest ãŒãªãã¦ã‚‚å®Ÿè¡Œå¯èƒ½ã§ã™ã€‚\n")
    
    success = run_all_tests()
    
    if success:
        print("\nğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        sys.exit(0)
    else:
        print("\nâŒ ã„ãã¤ã‹ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
        sys.exit(1)
